{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import snntorch as snn\n",
    "from snntorch import functional as SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChirpletDataset():\n",
    "    \"\"\" loading the chirplet plots and labels from the corresponding csv file\n",
    "        each csv file contains the corresponding label for each chirplet plot on the 4th or last column\n",
    "        after extracting the labels, converting the strings to int label as 0 1 2 \n",
    "        because the tensor type only contains numeric values \n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, label_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # filenames without extension\n",
    "        self.filenames = [os.path.splitext(f)[0] for f in os.listdir(img_dir) if f.endswith('.png')]\n",
    "        \n",
    "        # mapping of unique labels to integers\n",
    "        self.label_mapping = self._create_label_mapping()\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        unique_labels = set()\n",
    "        for filename in self.filenames:\n",
    "            label_path = os.path.join(self.label_dir, filename + '.csv')\n",
    "            label_df = pd.read_csv(label_path, header=None)\n",
    "            label = label_df.iloc[0, -1]\n",
    "            unique_labels.add(label)\n",
    "        return {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.filenames[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name + '.png')\n",
    "        label_path = os.path.join(self.label_dir, img_name + '.csv')\n",
    "        \n",
    "        # Convert image to grayscale\n",
    "        image = Image.open(img_path).convert('L')\n",
    "\n",
    "        label_df = pd.read_csv(label_path, header=None)\n",
    "        label = label_df.iloc[0, -1]  \n",
    "\n",
    "        label_int = self.label_mapping[label]\n",
    "\n",
    "        label_tensor = torch.tensor(label_int, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label_tensor\n",
    "\n",
    "# Training Parameters\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "trainDataPath = './data/chirplet_plots/train/'\n",
    "testDataPath = './data/chirplet_plots/test/'\n",
    "labelPath = './data/audio_dataset/'\n",
    "\n",
    "# Data Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),  # convert the image to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # (mean, std) for grayscale images\n",
    "])\n",
    "\n",
    "# initialize dataset and DataLoader\n",
    "train_dataset = ChirpletDataset(img_dir=trainDataPath, label_dir=labelPath, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = ChirpletDataset(img_dir=testDataPath, label_dir=labelPath, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# training dataloader\n",
    "for images, labels in train_loader:\n",
    "    print(f\"shapes -> images: {images.shape}, labels: {labels.shape}\")\n",
    "    print(f\"label values in a single batch: {labels}\")\n",
    "    break\n",
    "\n",
    "print(f\"total labels: {len(labels)} \\t label type: {type(labels)}\")\n",
    "print(f\"total batches: {len(train_loader)}\")\n",
    "print(f\"unique classes: {len(train_dataset.label_mapping)}\")\n",
    "\n",
    "# testing dataloader\n",
    "for images, labels in test_loader:\n",
    "    print(f\"\\nshapes -> images: {images.shape}\")\n",
    "    print(f\"label values in a single batch: {labels}\")\n",
    "    break\n",
    "\n",
    "print(f\"total batches: {len(test_loader)}\")\n",
    "print(f\"unique classes: {len(test_dataset.label_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_tensors(train_loader, test_loader):\n",
    "    \"\"\" saving as tensors rather than numpy format to avoid numpy to tensor conversion\n",
    "        ...\n",
    "    \"\"\"\n",
    "    # empty lists to hold the training images and labels\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "\n",
    "    # loop through each batch of training data\n",
    "    for images, labels in train_loader:\n",
    "        # Append the tensors directly without converting to numpy\n",
    "        train_images.append(images)\n",
    "        train_labels.append(labels)\n",
    "\n",
    "    # create empty lists for test images and labels\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "\n",
    "    # loop through each batch of testing data\n",
    "    for images, labels in test_loader:\n",
    "        # Append the tensors directly\n",
    "        test_images.append(images)\n",
    "        test_labels.append(labels)\n",
    "\n",
    "    # concatenate all training and test tensors\n",
    "    train_images_tensor = torch.cat(train_images, dim=0)\n",
    "    train_labels_tensor = torch.cat(train_labels, dim=0)\n",
    "    test_images_tensor = torch.cat(test_images, dim=0)\n",
    "    test_labels_tensor = torch.cat(test_labels, dim=0)\n",
    "\n",
    "    # save the tensors using torch.save()\n",
    "    torch.save(train_images_tensor, './data/dump/train_images.pt')\n",
    "    torch.save(train_labels_tensor, './data/dump/train_labels.pt')\n",
    "    torch.save(test_images_tensor, './data/dump/test_images.pt')\n",
    "    torch.save(test_labels_tensor, './data/dump/test_labels.pt')\n",
    "# Call the function to save the preprocessed data as tensors\n",
    "save_to_tensors(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the numpy files to input in the model and converting from numpy to tensor\n",
    "train_images_tensor = torch.load('./data/dump/train_images.pt')\n",
    "train_labels_tensor = torch.load('./data/dump/train_labels.pt')\n",
    "test_images_tensor = torch.load('./data/dump/test_images.pt')\n",
    "test_labels_tensor = torch.load('./data/dump/test_labels.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Model parameters\n",
    "# # Model config hyperparameters\n",
    "# batch_size = 3\n",
    "# num_steps = 25\n",
    "# num_epochs = 5 \n",
    "# alpha = 0.9\n",
    "# beta = 0.85\n",
    "# # using gpu\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# # SNN Network\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "#         super().__init__()\n",
    "\n",
    "#         # Initialize layers\n",
    "#         self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "#         self.lif1 = snn.Leaky(beta=beta)\n",
    "#         self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "#         self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         mem1 = self.lif1.init_leaky()\n",
    "#         mem2 = self.lif2.init_leaky()\n",
    "\n",
    "#         spk2_rec = []\n",
    "#         mem2_rec = []\n",
    "\n",
    "#         for _ in range(num_steps):\n",
    "#             cur1 = self.fc1(x)\n",
    "#             spk1, mem1 = self.lif1(cur1, mem1)\n",
    "#             cur2 = self.fc2(spk1)\n",
    "#             spk2, mem2 = self.lif2(cur2, mem2)\n",
    "#             spk2_rec.append(spk2)\n",
    "#             mem2_rec.append(mem2)\n",
    "\n",
    "#         return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "\n",
    "# num_inputs = 28 * 28  \n",
    "# num_hidden = 1000\n",
    "# num_outputs = len(train_dataset.label_mapping)  \n",
    "\n",
    "# # Initialize Network\n",
    "# net = Net(num_inputs, num_hidden, num_outputs).to(device)\n",
    "# # Initialize Optimizer\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n",
    "# # Define the loss function\n",
    "# loss_fn = SF.ce_rate_loss()\n",
    "\n",
    "# # Training Loop\n",
    "# for epoch in range(num_epochs):\n",
    "#     total_loss = 0\n",
    "#     for i, (images, labels) in enumerate(train_loader):\n",
    "#         images = images.view(-1, 28*28).to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         # Forward pass\n",
    "#         spk_rec, mem_rec = net(images)\n",
    "        \n",
    "#         loss = torch.zeros((1), dtype=torch.float, device=device)\n",
    "#         for step in range(num_steps):\n",
    "#             loss += loss_fn(mem_rec[step], labels)\n",
    "\n",
    "#         # Gradient calculation + weight update\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Print the results\n",
    "#         if (i+1) % 100 == 0:\n",
    "#             avg_loss = total_loss / 100\n",
    "#             print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Avg Loss: {avg_loss:.4f}')\n",
    "#             total_loss = 0\n",
    "\n",
    "# # Evaluation function\n",
    "# def test_accuracy(data_loader, net, num_steps):\n",
    "#     with torch.no_grad():\n",
    "#         total = 0\n",
    "#         acc = 0\n",
    "#         net.eval()\n",
    "        \n",
    "#         for data, targets in data_loader:\n",
    "#             data = data.view(-1, 28*28).to(device)\n",
    "#             targets = targets.to(device)\n",
    "#             spk_rec, _ = net(data)\n",
    "            \n",
    "#             acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "#             total += spk_rec.size(1)\n",
    "\n",
    "#     return acc/total\n",
    "\n",
    "# # Test the model\n",
    "# test_acc = test_accuracy(train_loader, net, num_steps)\n",
    "# print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 47\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(spk2_rec, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), torch\u001b[38;5;241m.\u001b[39mstack(mem2_rec, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Load the network onto CUDA if available\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     49\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m))\n",
      "File \u001b[0;32m~/work/thesis/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1173\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1171\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/thesis/env/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/work/thesis/env/lib/python3.10/site-packages/torch/nn/modules/module.py:804\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 804\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/work/thesis/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1159\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1153\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1154\u001b[0m             device,\n\u001b[1;32m   1155\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1156\u001b[0m             non_blocking,\n\u001b[1;32m   1157\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1158\u001b[0m         )\n\u001b[0;32m-> 1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28 * 28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "\n",
    "# Temporal Dynamics\n",
    "num_steps = 25\n",
    "beta = 0.95\n",
    "dtype = torch.float\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = Net().to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "    loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "# clear previously stored gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# calculate the gradients\n",
    "loss_val.backward()\n",
    "\n",
    "# weight update\n",
    "optimizer.step()\n",
    "# calculate new network outputs using the same data\n",
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "# initialize the total loss value\n",
    "loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "\n",
    "# sum loss at every step\n",
    "for step in range(num_steps):\n",
    "    loss_val += loss(mem_rec[step], targets)\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.sum(dim=0).max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    if train:\n",
    "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
    "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
    "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
    "    print_batch_accuracy(data, targets, train=True)\n",
    "    print_batch_accuracy(test_data, test_targets, train=False)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        for step in range(num_steps):\n",
    "            loss_val += loss(mem_rec[step], targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            for step in range(num_steps):\n",
    "                test_loss += loss(test_mem[step], test_targets)\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "batch_size = 32\n",
    "num_steps = 25\n",
    "num_epochs = 10\n",
    "beta = 0.85\n",
    "learning_rate = 1e-3\n",
    "\n",
    "trainDataPath = './data/chirplet_plots/train/'\n",
    "testDataPath = './data/chirplet_plots/test/'\n",
    "labelPath = './data/audio_dataset/'\n",
    "\n",
    "# Data Preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Initialize datasets and DataLoaders\n",
    "train_dataset = ChirpletDataset(img_dir=trainDataPath, label_dir=labelPath, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = ChirpletDataset(img_dir=testDataPath, label_dir=labelPath, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Model parameters\n",
    "num_inputs = 28 * 28\n",
    "num_hidden = 1000\n",
    "num_outputs = len(train_dataset.label_mapping)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize Network\n",
    "net = Net(num_inputs, num_hidden, num_outputs, beta).to(device)\n",
    "\n",
    "# Initialize Optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999))\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = SF.ce_rate_loss()\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    net.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        print(f\"Batch {i+1}:\")\n",
    "        print(f\"Images shape: {images.shape}\")\n",
    "        print(f\"Labels shape: {labels.shape}\")\n",
    "        print(f\"Unique labels: {torch.unique(labels)}\")\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        spk_rec, mem_rec = net(images, num_steps)\n",
    "        \n",
    "        print(f\"spk_rec shape: {spk_rec.shape}\")\n",
    "        print(f\"mem_rec shape: {mem_rec.shape}\")\n",
    "\n",
    "        loss = torch.zeros((1), dtype=torch.float, device=device)\n",
    "        for step in range(num_steps):\n",
    "            print(f\"Step {step}:\")\n",
    "            print(f\"mem_rec[step] shape: {mem_rec[step].shape}\")\n",
    "            print(f\"labels shape: {labels.shape}\")\n",
    "            loss += loss_fn(mem_rec[step], labels)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print the results\n",
    "        if (i+1) % 100 == 0:\n",
    "            avg_loss = total_loss / 100\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Avg Loss: {avg_loss:.4f}')\n",
    "            total_loss = 0\n",
    "\n",
    "        # Break after the first batch to avoid flooding the output\n",
    "        break\n",
    "\n",
    "    # Break after the first epoch\n",
    "    break\n",
    "\n",
    "    # Test the model after each epoch\n",
    "    train_acc = test_accuracy(train_loader, net, num_steps, device)\n",
    "    test_acc = test_accuracy(test_loader, net, num_steps, device)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Accuracy: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
